{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1704672398398,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"ygVHggdoRuW-"},"outputs":[],"source":["# !pip install torch torchvision tensorboardX"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16322,"status":"ok","timestamp":1704672414718,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"jMAyx8UnS73s"},"outputs":[],"source":["import os\n","import glob\n","import random\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","from tqdm import tqdm\n","from IPython import display\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.functional import relu\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from torchvision import transforms\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2161,"status":"ok","timestamp":1704672416855,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"kJ_jpX6foWMG","outputId":"4aa044fd-890f-41d1-fdf9-d975abfd18b2"},"outputs":[],"source":["# Connect to Google Drive on Google Colab\n","# from google.colab import drive\n","# drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704672416855,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"QFO9Y3S_kX3V"},"outputs":[],"source":["# Clone the GitHub repository\n","# !git clone https://github.com/Elias-Buerger/cvproj.git"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704672416855,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"cjTjywjshM-P"},"outputs":[],"source":["DATA_PATH = \"./cvproj/data/\"\n","SAVE_PATH = \"drive/MyDrive/CV_5/\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704672416856,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"UHUqwGBBvmXg"},"outputs":[],"source":["# NOTE: This code deletes the last batch (i.e., numpy file - including target, \"_y\" file)! The dataloader will NOT work otherwise!!!\n","files_to_delete = [\"332.npy\", \"332_y.npy\"]\n","for file_to_delete in files_to_delete:\n","    file_to_delete_path = os.path.join(DATA_PATH, file_to_delete)\n","    if os.path.exists(file_to_delete_path):\n","        os.remove(file_to_delete_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704672416856,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"i1ipKFaUXXNc"},"outputs":[],"source":["class AOSDataset(Dataset):\n","    def __init__(self, file_list, target_path, transform=False):\n","        self.file_list = file_list\n","        self.target_path = target_path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.file_list) * 32\n","\n","    def preprocess_channel(self, channel):\n","        # Convert channel to PIL Image\n","        channel = Image.fromarray(channel)\n","\n","        # plt.imshow(channel, cmap=\"gray\")\n","        # plt.title(\"Original\")\n","        # plt.show()\n","\n","        # Contrast\n","        channel_contrast = np.array(TF.adjust_contrast(channel_data, 100))\n","\n","        # plt.imshow(channel_contrast, cmap=\"gray\")\n","        # plt.title(\"Contrast\")\n","        # plt.show()\n","\n","        # Brightness\n","        # channel_brightness = np.array(self.color_jitter_brightness(channel))\n","\n","        # Inversion\n","        # channel_inverted = np.array(TF.invert(channel))\n","\n","        # Histogram Equalization\n","        channel_equalized = np.array(TF.equalize(channel))\n","\n","        # plt.imshow(channel_equalized, cmap=\"gray\")\n","        # plt.title(\"Equalization\")\n","        # plt.show()\n","\n","        # Inversion and Histogram Equalization\n","        # channel_inverted_equalized = np.array(TF.equalize(TF.invert(channel)))\n","\n","        return channel_contrast, channel_equalized\n","\n","    def __getitem__(self, idx):\n","        file_idx = idx // 32  # Determine which file to load\n","        batch_idx = idx % 32  # Determine the index within the batch\n","\n","        data = np.load(self.file_list[file_idx])\n","        data = data[batch_idx]\n","\n","        target_idx = self.file_list[file_idx].split(\"/\")[-1].split(\".\")[0]\n","        target = np.load(os.path.join(self.target_path, f\"{target_idx}_y.npy\"))\n","        target = target[batch_idx]\n","\n","        # Apply preprocessing steps to each channel separately\n","        preprocessed_channels = []\n","        for channel in range(data.shape[0]):\n","            channel_data = data[1]\n","\n","            # Apply preprocessing steps\n","            preprocessed_contrast, preprocessed_equalized = self.preprocess_channel(channel_data)\n","\n","            preprocessed_channels.extend([preprocessed_contrast, preprocessed_equalized])\n","\n","        # Convert preprocessed_channels to a NumPy array\n","        preprocessed_channels = np.array(preprocessed_channels)\n","\n","        # Concatenate the original and preprocessed channels\n","        data = np.concatenate([data, preprocessed_channels], axis=0)\n","\n","        del preprocessed_channels\n","\n","        # Normalize\n","        data = torch.Tensor(data) / 255.0\n","        target = torch.Tensor(target).unsqueeze(0) / 255.0 # 1 x ...\n","\n","        # Clip values to the range [0, 1]\n","        data = torch.clamp(data, 0, 1)\n","        target = torch.clamp(target, 0, 1)\n","\n","        # Apply random augmentations\n","        if self.transform:\n","            angle = random.choice([0, 90, 180, 270])\n","            data = TF.rotate(data, angle)\n","            target = TF.rotate(target, angle)\n","\n","            if random.random() > 0.5:\n","                data = TF.hflip(data)\n","                target = TF.hflip(target)\n","\n","            if random.random() > 0.5:\n","                data = TF.vflip(data)\n","                target = TF.vflip(target)\n","\n","        return data, target"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704672416856,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"O0dZ9WAPTN26"},"outputs":[],"source":["# Define the local paths for data and targets within the cloned repository\n","data_path = DATA_PATH\n","target_path = DATA_PATH\n","\n","# Get all training files (ignoring \"_y.npy\")\n","file_list = glob.glob(os.path.join(data_path, \"*[!_y].npy\"))\n","\n","# Determine the split for training and test\n","split_idx = int(0.8 * len(file_list))\n","train_file_list = file_list[:split_idx]\n","test_file_list = file_list[split_idx:]\n","\n","# Create CustomDataset instances\n","train_dataset = AOSDataset(train_file_list, target_path, transform=True)\n","test_dataset = AOSDataset(test_file_list, target_path)\n","\n","# Create DataLoader instances\n","train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1704672417875,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"uZjBmNTeUQc7"},"outputs":[],"source":["# Retrieve samples if needed...\n","# for sample in train_loader:\n","#    sample"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704672417875,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"dWfqcxD3jHk1"},"outputs":[],"source":["# Source: https://github.com/milesial/Pytorch-UNet\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None, kernel_size=3, padding=1):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, padding=padding),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.SiLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=kernel_size, padding=padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.SiLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # NOTE: If bilinear, use the normal convolutions to reduce the number of channels!\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","        self.gate = nn.Conv2d(in_channels // 2, in_channels // 2, kernel_size=3, padding=1)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # Input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n","        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","\n","        x2 = x2 * torch.sigmoid(self.gate(x1)) # F.softmax(self.gate(x1), dim=1)\n","\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class Out(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(Out, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704672417875,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"tqfaiQErixjn"},"outputs":[],"source":["# Source: https://github.com/milesial/Pytorch-UNet\n","class UNet(nn.Module):\n","    def __init__(self, n_channels_in, n_channels_out, bilinear=True):\n","        super(UNet, self).__init__()\n","        self.n_channels_in = n_channels_in\n","        self.n_channels_out = n_channels_out\n","        self.bilinear = bilinear\n","\n","        self.inc = DoubleConv(n_channels_in, 64)\n","\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","\n","        self.out = Out(64, n_channels_out)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","\n","        x = self.out(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704672417875,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"SH5yP7iHV8BQ"},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir=runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"elapsed":23019733,"status":"ok","timestamp":1704749499712,"user":{"displayName":"Ákos Filakovszky","userId":"16949903218463042694"},"user_tz":-60},"id":"iFHhEcw-TQVt","outputId":"dd0afa8d-8818-473c-fbdb-6dca2eef7ef2"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = UNet(9, 1).to(device) # UNet(12, 1).to(device)\n","criterion = nn.MSELoss() # DiceLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","# TensorBoard\n","writer = SummaryWriter()\n","\n","# Initialize a figure for plotting\n","fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n","ax[0].set_title(\"Input\")\n","ax[1].set_title(\"Target\")\n","ax[2].set_title(\"Output\")\n","\n","# Training loop\n","num_epochs = 50\n","log_interval = 100\n","for epoch in range(num_epochs):\n","    # running_loss = 0.0\n","    model.train()\n","    with tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n","        for batch_idx, (batch_data, batch_targets) in enumerate(train_loader):\n","            batch_data, batch_targets = batch_data.to(device), batch_targets.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(batch_data)\n","            # outputs = torch.clamp(outputs, 0, 1) # Clip values to [0, 1]\n","            loss = criterion(outputs, batch_targets)\n","            loss.backward()\n","            # nn.utils.clip_grad_value_(model.parameters(), 0.1) # Clip gradients?\n","            optimizer.step()\n","\n","            # running_loss += loss.item()\n","\n","            if batch_idx % log_interval == 0 and batch_idx > 0:\n","                # Monitor loss - NOTE: Disabled for increased efficiency\n","                # avg_loss = running_loss / log_interval\n","                # print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx-log_interval+1}-{batch_idx}], Loss: {avg_loss}\")\n","                # writer.add_scalar(\"Loss/train\", avg_loss, epoch * len(train_loader) + batch_idx)\n","\n","                # Log images to TensorBoard\n","                # writer.add_images(\"Input/train\", batch_data, epoch * len(train_loader) + batch_idx) # NOTE: Would have to be fixed because of the incresead number of channels...\n","                writer.add_images(\"Target/train\", batch_targets, epoch * len(train_loader) + batch_idx)\n","                writer.add_images(\"Output/train\", torch.clamp(outputs, 0, 1), epoch * len(train_loader) + batch_idx)\n","\n","                # Clear previous plots\n","                display.clear_output()\n","\n","                # Plot input, target, and output\n","                ax[0].imshow(TF.to_pil_image(batch_data[0][0].cpu()), cmap=\"gray\")\n","                ax[0].set_title(\"Input\")\n","\n","                ax[1].imshow(TF.to_pil_image(batch_targets[0].cpu()), cmap=\"gray\")\n","                ax[1].set_title(\"Target\")\n","\n","                ax[2].imshow(TF.to_pil_image(torch.clamp(outputs[0], 0, 1).cpu()), cmap=\"gray\")\n","                ax[2].set_title(\"Output\")\n","\n","                if batch_idx % (log_interval * 1) == 0 and batch_idx > 0:\n","                    # Save the figure to the Google Drive folder\n","                    path = f\"{SAVE_PATH}plot_epoch_{epoch}_batch_{batch_idx}_0.png\"\n","                    fig.savefig(path)\n","\n","                # Display the updated plot\n","                display.display(fig)\n","\n","                # running_loss = 0.\n","\n","            del batch_data, batch_targets, outputs # Release variables\n","            # torch.cuda.empty_cache()\n","\n","    # Update learning rate\n","    scheduler.step()\n","\n","    # Log to TensorBoard\n","    writer.add_scalar(\"Loss/train\", loss.item(), epoch)\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        for batch_data, batch_targets in test_loader:\n","            batch_data, batch_targets = batch_data.to(device), batch_targets.to(device)\n","            outputs = model(batch_data)\n","            outputs = torch.clamp(outputs, 0, 1) # Clip values to [0, 1]\n","            val_loss += criterion(outputs, batch_targets)\n","\n","            del batch_data, batch_targets, outputs # Release variables\n","            torch.cuda.empty_cache()\n","\n","        avg_val_loss = val_loss / len(test_loader)\n","        print(f\"Validation Loss: {avg_val_loss}\")\n","        writer.add_scalar(\"Loss/test\", avg_val_loss, epoch)\n","\n","    # Save model weights\n","    model_save_path = f\"{SAVE_PATH}unet_epoch_{epoch}.pth\"\n","    torch.save(model.state_dict(), model_save_path)\n","    print(f\"Model saved at epoch {epoch}\")\n","\n","# Close TensorBoard writer\n","writer.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
